{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터 기본 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       " 0        100        160     1.6000          0          0          0   \n",
       " 1         20         83     4.1500          1          0          0   \n",
       " 2         99        150     1.5151          1          0          0   \n",
       " 3         40         40     1.0000          0          0          0   \n",
       " 4         12        234    19.5000          1          0          0   \n",
       " \n",
       "    feature_7  feature_8  feature_9  feature_10  ...  feature_1550  \\\n",
       " 0          0          0          0           0  ...             0   \n",
       " 1          0          0          0           1  ...             0   \n",
       " 2          0          0          0           0  ...             0   \n",
       " 3          0          0          0           0  ...             0   \n",
       " 4          0          0          0           0  ...             0   \n",
       " \n",
       "    feature_1551  feature_1552  feature_1553  feature_1554  feature_1555  \\\n",
       " 0             0             0             0             0             0   \n",
       " 1             0             0             0             0             1   \n",
       " 2             0             0             0             0             0   \n",
       " 3             0             0             0             0             0   \n",
       " 4             0             0             0             0             0   \n",
       " \n",
       "    feature_1556  feature_1557  feature_1558  Class  \n",
       " 0             0             0             0      0  \n",
       " 1             0             0             0      0  \n",
       " 2             0             0             0      0  \n",
       " 3             0             0             0      0  \n",
       " 4             0             0             0      0  \n",
       " \n",
       " [5 rows x 1559 columns],\n",
       "    feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       " 0       60.0      468.0     7.8000        1.0          0          0   \n",
       " 1      108.0      179.0     1.6574        1.0          0          0   \n",
       " 2        1.0        1.0     2.0000        0.0          0          0   \n",
       " 3       60.0      468.0     7.8000        1.0          0          0   \n",
       " 4       60.0      120.0     2.0000        1.0          0          0   \n",
       " \n",
       "    feature_7  feature_8  feature_9  feature_10  ...  feature_1549  \\\n",
       " 0          0          0          0           0  ...             0   \n",
       " 1          0          0          0           0  ...             0   \n",
       " 2          0          0          0           0  ...             0   \n",
       " 3          0          0          0           0  ...             0   \n",
       " 4          0          0          0           0  ...             0   \n",
       " \n",
       "    feature_1550  feature_1551  feature_1552  feature_1553  feature_1554  \\\n",
       " 0             0             0             0             0             0   \n",
       " 1             0             0             0             0             0   \n",
       " 2             0             0             0             0             0   \n",
       " 3             0             0             0             0             0   \n",
       " 4             0             0             0             0             0   \n",
       " \n",
       "    feature_1555  feature_1556  feature_1557  feature_1558  \n",
       " 0             0             0             0             0  \n",
       " 1             0             0             0             0  \n",
       " 2             0             0             0             0  \n",
       " 3             0             0             0             0  \n",
       " 4             0             0             0             0  \n",
       " \n",
       " [5 rows x 1558 columns])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_file_path = '/Users/imdaegyeong/Desktop/archive/Train.csv'\n",
    "test_file_path = '/Users/imdaegyeong/Desktop/archive/Test.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_file_path)\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "\n",
    "train_data_info = train_data.head()\n",
    "test_data_info = test_data.head()\n",
    "\n",
    "train_data_info, test_data_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Series([], dtype: int64), Series([], dtype: int64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측값 확인\n",
    "train_missing_values = train_data.isnull().sum()\n",
    "test_missing_values = test_data.isnull().sum()\n",
    "\n",
    "# 결측값이 존재하는 열과 그 개수만 확인\n",
    "train_missing = train_missing_values[train_missing_values > 0]\n",
    "test_missing = test_missing_values[test_missing_values > 0]\n",
    "\n",
    "train_missing, test_missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 피어슨 상관계수로 상관관계 높은 특성 도출, 먼저 단순하게 테스트 하기 위해 상위 10개로만 테스트 진행\n",
    "#### PCA 방법 도입 > 10가지로 국한하지 말것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class           1.000000\n",
       "feature_1400    0.424960\n",
       "feature_1244    0.397658\n",
       "feature_1154    0.368261\n",
       "feature_1048    0.364530\n",
       "feature_1144    0.364444\n",
       "feature_1345    0.357316\n",
       "feature_1423    0.356812\n",
       "feature_1425    0.356812\n",
       "feature_1199    0.356812\n",
       "feature_1155    0.356812\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 피어슨 상관계수를 이용하여 상관관계 분석\n",
    "correlation_matrix = train_data.corr()\n",
    "\n",
    "# Class와의 상관관계가 높은 상위 10개의 특성을 추출\n",
    "top_features = correlation_matrix[\"Class\"].abs().sort_values(ascending=False).head(11)  # Class 포함\n",
    "top_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이상치를 IQR 기법으로 처리하려 하였으나, 데이터가 0과 1로 이루어진 이진 데이터 이므로 다른 방법을 찾아야 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 기반 이상치 탐지 : 데이터 학습 과정에서 이상치를 감지하고, 모델이 그 영향을 최소화 하도록 하는 방식. 이상치를 명시적으로 하지 않고도 모델이 역할 수행. 이는 이진 데이터에서 적합하다. 데이터가 이진 또는 다차원일때 추천. 이 경우 랜덤 포레스트나 XGBoost 모델 자체로 이상치 처리하기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 랜덤포레스트 / 상위 10개 특성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9228544295647694"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 랜덤 포레스트 모델 생성\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 상위 10개의 선택된 특성으로 모델 학습\n",
    "X_rf = train_data[selected_features]\n",
    "y_rf = train_data['Class']\n",
    "\n",
    "# 교차 검증을 사용하여 모델 성능 평가 (5-fold 교차 검증)\n",
    "cross_val_scores = cross_val_score(rf_model, X_rf, y_rf, cv=5)\n",
    "\n",
    "# 교차 검증 평균 성능 확인\n",
    "cross_val_scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9228544295647694"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 피어슨 상관계수를 이용하여 상관관계 분석\n",
    "correlation_matrix = train_data.corr()\n",
    "\n",
    "# Class와의 상관관계가 높은 상위 10개의 특성을 추출\n",
    "top_features = correlation_matrix[\"Class\"].abs().sort_values(ascending=False).head(11)  # Class 포함\n",
    "\n",
    "# 상위 10개의 특성만 선택\n",
    "selected_features = ['feature_1400', 'feature_1244', 'feature_1154', 'feature_1048', 'feature_1144', \n",
    "                     'feature_1345', 'feature_1423', 'feature_1425', 'feature_1199', 'feature_1155']\n",
    "\n",
    "# 랜덤 포레스트 모델 생성\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 상위 10개의 선택된 특성으로 모델 학습\n",
    "X_rf = train_data[selected_features]\n",
    "y_rf = train_data['Class']\n",
    "\n",
    "# 교차 검증을 사용하여 모델 성능 평가 (5-fold 교차 검증)\n",
    "cross_val_scores = cross_val_score(rf_model, X_rf, y_rf, cv=5)\n",
    "\n",
    "# 교차 검증 평균 성능 확인\n",
    "cross_val_scores.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 교차검증 : 5-fold 교차검증 : 훈련데이터를 5개부분으로 나누고, 매번 다른 하나의 부분을 검증 데이터로 사용하여 성능을 평가한 후 평균을 내는 방법. 80:20 이렇게 하면 모델이 훈련 데이터에 오버피팅 되지않고 신뢰성 있는 성능 평가가 가능. 성능 확인을 위해 교차검증을 진행한것. 최종 성능은 테스트 데이터를 사용. 모델이 훈련데이터에서 얼마나 안정적인 성능을 낼수 있는지 확인하는 과정이 교차검증. 정밀도, 재현율, f1-score등 다른 성능 지표도 함께 평가해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 이상치 탐지 성능을 높이기 위해 랜덤포레스트에서 선택 가능한 방법\n",
    "###### 1. 하이퍼파라미터 튜닝\n",
    "###### 2. 이상치 탐지에 집중한 임계값 조정\n",
    "###### 3. 앙상블 기법 활용 (내부적으로 이용)\n",
    "###### 4. 데이터 불균형 처리\n",
    "###### 5. 특성 중요도 분석 및 추가 특성 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 하이퍼 파라미터 튜닝\n",
    "###### GridSearchCV : 완전탐색으로 최적의 파라미터 찾기/ 시간이 오래 걸릴수 있다.\n",
    "###### RandomizedSearchCV : 설정된 범위 내에서 임의의 파라미터 조합을 일부만 탐색하여 최적의 파라미터를 빠르게 찾을 수 있다. 최적의 파라미터를 놓칠수도."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV Best Params: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomizedSearchCV Best Params: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 랜덤 포레스트 모델 설정\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 하이퍼파라미터 범위 설정\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# 1. GridSearchCV 설정\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "\n",
    "# 2. RandomizedSearchCV 설정 (랜덤 탐색에서 반복 횟수 10 설정)\n",
    "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_grid, n_iter=10, cv=5, scoring='f1', n_jobs=-1, random_state=42)\n",
    "\n",
    "# 실행\n",
    "grid_search.fit(X_rf, y_rf)\n",
    "random_search.fit(X_rf, y_rf)\n",
    "\n",
    "# 최적의 파라미터 확인\n",
    "best_params_grid = grid_search.best_params_\n",
    "best_params_random = random_search.best_params_\n",
    "\n",
    "print(\"GridSearchCV Best Params:\", best_params_grid)\n",
    "print(\"RandomizedSearchCV Best Params:\", best_params_random)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GridSearchCV로 나온 최적의 파라미터로 모델 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1-Score: 0.41536186575614426\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 최적의 파라미터로 랜덤 포레스트 모델 생성\n",
    "rf_best_grid = RandomForestClassifier(\n",
    "    max_depth=10,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=4,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "rf_best_grid.fit(X_rf, y_rf)\n",
    "\n",
    "# 교차 검증을 사용하여 F1-Score 계산 (5-fold 교차 검증)\n",
    "f1_scores = cross_val_score(rf_best_grid, X_rf, y_rf, cv=5, scoring='f1')\n",
    "\n",
    "# F1-Score 평균 계산\n",
    "f1_score_mean = f1_scores.mean()\n",
    "print(\"Average F1-Score:\", f1_score_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 최적의 임계값을 찾기. 현재 f1-score 값의 결과로 보았을때 이상치 탐지 성능이 아직 최적화 되지 않았을 가능성이 높음\n",
    "###### 정밀도 : 양성(이상치)라고 예측한것 중에 실제 양성의 비율\n",
    "###### 재현율 : 양성(이상치) 데이터 중에서 모델이 정확히 탐지한 비율\n",
    "###### 지금 데이터에서 이상치가 적고 정상데이터가 많기 때문에 이상치 탐지를 잘 못하고 있을 가능성이 높다. 따라서 재현율이 낮을 가능성이 높은것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.1799613075205644\n",
      "Max F1-Score: 0.49498327759197325\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "# 예측 확률값을 계산하여 임계값 조정을 위한 준비\n",
    "y_rf_probs = rf_best_grid.predict_proba(X_rf)[:, 1]  # 양성 클래스(1)의 확률값만 추출\n",
    "\n",
    "# Precision-Recall Curve를 계산하여 다양한 임계값에서의 정밀도, 재현율 확인\n",
    "precision, recall, thresholds = precision_recall_curve(y_rf, y_rf_probs)\n",
    "\n",
    "# F1-Score를 기반으로 최적의 임계값을 선택\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "\n",
    "print(\"Best Threshold:\", best_threshold)\n",
    "print(\"Max F1-Score:\", max(f1_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### f1-score 이 0.494 정도로 개선 되었지만 현재 데이터에서 이상치가 적고 정상데이터가 많으므로 이상치 탐지를 놓치는 경우가 발생. 이 경우 재현율이 낮아져 f1-score가 낮게 나오게 됨.따라서 모델 복잡성을 높이는 등의 방법을 사용하는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 지금 상황에서 이상치 데이터가 적으므로 SMOTE와 같은 오버샘플링 기법을 이용하여 모델 이상치를 더 잘 학습 시키거나, 언더샘플링을 통해 정상 데이터를 줄여서 데이터 균형을 맞추고 이상치 탐지 성능을 향상 시키는 방법이 있음 그게 아니라면 XGBoost와 같은 더 강력한 모델을 사용하는 것이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SMOTE를 이용하여 오버샘플링 진행\n",
    "\n",
    "###### SMOTE 원리: 1. K-NN에 기반하여 각 소수 클래스 샘플의 k개의 가까운 이웃을 찾는. 2. 새로운 샘플을 생성  : 원래의 소수 클래스 샘플과 그 이웃 샘플 사이의 직선상에 새로운 샘플을 생성, 즉 기존 데이터 포인트들 사이에 새로운 데이터를 삽입하는 방식. 3. 균형 맞추기 : 소수 데이터를 점진적으로 늘려 데이터의 불균형을 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score with SMOTE: 0.6391543416329368\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# SMOTE 적용\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_rf, y_rf)\n",
    "\n",
    "# 랜덤 포레스트 모델 학습 (GridSearchCV에서 찾은 최적의 파라미터 사용)\n",
    "rf_model_smote = RandomForestClassifier(\n",
    "    max_depth=10,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=4,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# SMOTE가 적용된 데이터로 모델 학습\n",
    "rf_model_smote.fit(X_resampled, y_resampled)\n",
    "\n",
    "# 교차 검증을 사용하여 F1-Score 계산 (5-fold 교차 검증)\n",
    "f1_scores_smote = cross_val_score(rf_model_smote, X_resampled, y_resampled, cv=5, scoring='f1')\n",
    "\n",
    "# F1-Score 평균 확인\n",
    "f1_score_smote_mean = f1_scores_smote.mean()\n",
    "print(\"F1-Score with SMOTE:\", f1_score_smote_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 그리드 서치로 다시 하이퍼파라미터 튜닝. f1-score를 높이기 위함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params with SMOTE: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 랜덤 포레스트 모델 설정 (SMOTE 적용 후)\n",
    "rf_model_smote = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 하이퍼파라미터 범위 설정\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# GridSearchCV 설정\n",
    "grid_search_smote = GridSearchCV(estimator=rf_model_smote, param_grid=param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "\n",
    "# GridSearchCV 실행\n",
    "grid_search_smote.fit(X_resampled, y_resampled)\n",
    "\n",
    "# 최적의 파라미터 확인\n",
    "best_params_grid_smote = grid_search_smote.best_params_\n",
    "print(\"Best Params with SMOTE:\", best_params_grid_smote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold with SMOTE: 0.3572539068623872\n",
      "Max F1-Score with SMOTE: 0.6666666666666666\n",
      "Best Precision: 0.5\n",
      "Best Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "# 새로 찾은 최적의 하이퍼파라미터로 랜덤 포레스트 모델 학습\n",
    "rf_best_smote = RandomForestClassifier(\n",
    "    max_depth=10,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=4,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# SMOTE가 적용된 데이터로 모델 학습\n",
    "rf_best_smote.fit(X_resampled, y_resampled)\n",
    "\n",
    "# 예측 확률값을 계산하여 임계값 조정 준비\n",
    "y_rf_probs_smote = rf_best_smote.predict_proba(X_resampled)[:, 1]  # 양성 클래스(1)의 확률값만 추출\n",
    "\n",
    "# Precision-Recall Curve를 계산하여 다양한 임계값에서의 정밀도, 재현율 확인\n",
    "precision_smote, recall_smote, thresholds_smote = precision_recall_curve(y_resampled, y_rf_probs_smote)\n",
    "\n",
    "# F1-Score를 기반으로 최적의 임계값을 선택\n",
    "f1_scores_smote = 2 * (precision_smote * recall_smote) / (precision_smote + recall_smote)\n",
    "best_threshold_smote = thresholds_smote[np.argmax(f1_scores_smote)]\n",
    "\n",
    "# 최적의 임계값과 최대 F1-Score 확인\n",
    "print(\"Best Threshold with SMOTE:\", best_threshold_smote)\n",
    "print(\"Max F1-Score with SMOTE:\", max(f1_scores_smote))\n",
    "\n",
    "# 정밀도와 재현율 출력\n",
    "best_precision = precision_smote[np.argmax(f1_scores_smote)]\n",
    "best_recall = recall_smote[np.argmax(f1_scores_smote)]\n",
    "print(\"Best Precision:\", best_precision)\n",
    "print(\"Best Recall:\", best_recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 비정상적인 재현율로 다시 임계값 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision with higher threshold: 0.9089874857792947\n",
      "Recall with higher threshold: 0.49320987654320986\n",
      "F1-Score with higher threshold: 0.6394557823129251\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# 임계값을 더 높게 설정하여 재조정\n",
    "higher_threshold = best_threshold_smote + 0.1  # 기존 임계값보다 0.1 높여서 시도\n",
    "\n",
    "# 새로운 임계값으로 예측 수행 (확률이 higher_threshold 이상인 경우만 양성으로 예측)\n",
    "y_pred_higher_threshold = (y_rf_probs_smote >= higher_threshold).astype(int)\n",
    "\n",
    "# 정밀도, 재현율, F1-Score 계산\n",
    "precision_higher = precision_score(y_resampled, y_pred_higher_threshold)\n",
    "recall_higher = recall_score(y_resampled, y_pred_higher_threshold)\n",
    "f1_higher = f1_score(y_resampled, y_pred_higher_threshold)\n",
    "\n",
    "# 성능 출력\n",
    "print(\"Precision with higher threshold:\", precision_higher)\n",
    "print(\"Recall with higher threshold:\", recall_higher)\n",
    "print(\"F1-Score with higher threshold:\", f1_higher)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 언더샘플링을 해보고 성능 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Precision (UnderSampling): 0.5\n",
      "Best Recall (UnderSampling): 1.0\n",
      "Best F1-Score (UnderSampling): 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "# 언더샘플링 적용\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled_under, y_resampled_under = undersampler.fit_resample(X_rf, y_rf)\n",
    "\n",
    "# 언더샘플링된 데이터로 랜덤 포레스트 모델 학습 (최적의 하이퍼파라미터 적용)\n",
    "rf_model_under = RandomForestClassifier(\n",
    "    max_depth=10,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=4,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf_model_under.fit(X_resampled_under, y_resampled_under)\n",
    "\n",
    "# 예측 확률값 계산\n",
    "y_rf_probs_under = rf_model_under.predict_proba(X_resampled_under)[:, 1]  # 양성 클래스(1)의 확률값만 추출\n",
    "\n",
    "# Precision-Recall Curve를 계산하여 임계값 조정\n",
    "precision_under, recall_under, thresholds_under = precision_recall_curve(y_resampled_under, y_rf_probs_under)\n",
    "\n",
    "# F1-Score를 기반으로 최적의 임계값 선택\n",
    "f1_scores_under = 2 * (precision_under * recall_under) / (precision_under + recall_under)\n",
    "best_threshold_under = thresholds_under[np.argmax(f1_scores_under)]\n",
    "\n",
    "# 최적의 임계값에서 예측 수행\n",
    "y_pred_under = (y_rf_probs_under >= best_threshold_under).astype(int)\n",
    "\n",
    "# 성능 평가 (정밀도, 재현율, F1-Score)\n",
    "precision_under_final = precision_score(y_resampled_under, y_pred_under)\n",
    "recall_under_final = recall_score(y_resampled_under, y_pred_under)\n",
    "f1_under_final = f1_score(y_resampled_under, y_pred_under)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Best Precision (UnderSampling):\", precision_under_final)\n",
    "print(\"Best Recall (UnderSampling):\", recall_under_final)\n",
    "print(\"Best F1-Score (UnderSampling):\", f1_under_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 랜덤 포레스트 결과 : 하이퍼파라미터와 임계치를 조정을 하였음에도 F1-score 및 정밀도 재현율 부분에서 높은 값을 나타내지 못하는것 같아 다른 모델을 사용하는것이 좋을것으로 예상됨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
